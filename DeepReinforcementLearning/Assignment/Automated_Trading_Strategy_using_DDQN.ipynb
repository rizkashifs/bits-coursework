{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement:** Automated Trading Strategy using DDQN\t\t     **(Total = 8 Marks)**\n",
        "\n",
        "## **Background:**\n",
        "In finance, automated trading systems are used to execute trades in financial markets based on predefined rules. These systems often employ quantitative strategies that rely on analyzing market data to make trading decisions. However, designing effective trading strategies manually can be challenging due to the complex and dynamic nature of financial markets.\n",
        "\n",
        "## **Objective:**\n",
        "The objective is to develop an automated trading system that can learn to buy, sell or hold the stocks directly from historical market data."
      ],
      "metadata": {
        "id": "Eplo68zIwsE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Choice Instructions:**\n",
        "You need to select a trading dataset of Klines daily data only as it suits the problem statement. Select the historical data of 30 mins for one month for any stock from the list.  The link for downloading the dataset can be found here (https://data.binance.vision/?prefix=data/spot/daily/klines/.)\n",
        "The details of Klines daily data is given on github link: https://github.com/binance/binance-public-data/\n",
        "**(Use only Klines dataset only)**"
      ],
      "metadata": {
        "id": "Vp0-7BGGw-kt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementation:**\n",
        "1. Mention the dataset name and the time limit you have chosen along with the link. Also print its statistics. **(1 M)**\n",
        "2. You are required to implement DDQN on the dataset.\n",
        "3. You are requested to implement only the DRL approach with DDQN. **(5 M)**\n",
        "  * Design a Trading Environment. (0.5 M)\n",
        "  * State the state space and action space (0.5 M)\n",
        "  * Clearly  define the parameters  used for training an AI agent. (1 M)\n",
        "    * Number of episodes\n",
        "    * Max capacity of replay memory\n",
        "    * Batch size\n",
        "    * Period of Q target network updates\n",
        "    * Discount factor for future rewards\n",
        "    * Initial value for epsilon of the e-greedy\n",
        "    * Final value for epsilon of the e-greedy\n",
        "    * Learning rate of ADAM optimizer, and etc..\n",
        "  * Define the functions for Buy, Sell and Hold actions. (1.5 M)\n",
        "  * Implement a replay buffer for storing the experiences. (0.5 M)\n",
        "  * Design the Main Network (0.5 M)\n",
        "  * Target Network (0.5 M)\n",
        "8. Plot the graph for agents for buying and selling of the stock. **(1M)**\n",
        "9. Conclude your assignment with your analysis consisting of at least 200 words by summarizing your findings of the assignment. **(1 M)**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A5DUC8v1xS9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Info**"
      ],
      "metadata": {
        "id": "onZNhyu2zVM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------start your code below this line-----------"
      ],
      "metadata": {
        "id": "m446kWWczYN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Trading Env**"
      ],
      "metadata": {
        "id": "cDQaMQyozKCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Prt5MZkBVaz"
      },
      "outputs": [],
      "source": [
        "#-------start your code below this line-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialized Parameters**"
      ],
      "metadata": {
        "id": "HEKUli9jzbpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------start your code below this line-----------"
      ],
      "metadata": {
        "id": "gWFTIApJzfx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Double DQN Implementation code**"
      ],
      "metadata": {
        "id": "AqpBk1XRzhri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------start your code below this line-----------"
      ],
      "metadata": {
        "id": "RPIvkBLzzmP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Iterations**\n",
        "\n",
        "***Note: print all the episodes with the values of investment and buying. (if not printed then -1 will be done.)***\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "884cj7FDznLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------start your code below this line-----------"
      ],
      "metadata": {
        "id": "U2LvqS3Wz-Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot Graph of buying, selling and holding**"
      ],
      "metadata": {
        "id": "MuPv2ywd0ARq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------start your code below this line-----------"
      ],
      "metadata": {
        "id": "53u0zTRL0GP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion in 200 words**"
      ],
      "metadata": {
        "id": "12hVHaMM0HER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*`------------write your conclusion below this line-------------------`*"
      ],
      "metadata": {
        "id": "-qwaCWXj0KpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "1. https://www.analyticsvidhya.com/blog/2021/01/bear-run-or-bull-run-can-reinforcement-learning-help-in-automated-trading/\n",
        "2. https://github.com/ThibautTheate/An-Application-of-Deep-Reinforcement-Learning-to-Algorithmic-Trading/tree/main\n",
        "3. https://medium.com/datapebbles/building-a-trading-bot-with-deep-reinforcement-learning-drl-b9519a8ba2ac"
      ],
      "metadata": {
        "id": "0XjH9AZmy-oZ"
      }
    }
  ]
}